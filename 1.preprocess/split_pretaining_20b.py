"""
Pretraining 20B ì •í™• ë¶„í• 
IR 10B + ASM 10B
"""

import json
import random
from pathlib import Path

def load_all_metadata():
    base_dir = Path(".")
    parquet_dirs = sorted([d for d in base_dir.glob("test_parquet_*") if d.is_dir()])
    
    all_samples = []
    for parquet_dir in parquet_dirs:
        metadata_file = parquet_dir / "metadata.jsonl"
        if not metadata_file.exists():
            continue
        
        with open(metadata_file, 'r') as f:
            for line in f:
                data = json.loads(line)
                data['parquet'] = parquet_dir.name
                all_samples.append(data)
    
    return all_samples

def main():
    random.seed(42)
    
    print("=" * 70)
    print("Pretraining 20B ë°ì´í„°ì…‹ ë¶„í• ")
    print("=" * 70)
    
    all_samples = load_all_metadata()
    random.shuffle(all_samples)
    
    total_ir = sum(s['ir_tokens'] for s in all_samples)
    total_asm = sum(s['asm_tokens'] for s in all_samples)
    
    print(f"\nğŸ“¥ ì „ì²´: {len(all_samples):,}ê°œ")
    print(f"  IR:  {total_ir/1e9:.2f}B")
    print(f"  ASM: {total_asm/1e9:.2f}B")
    print(f"  í•©ê³„: {(total_ir + total_asm)/1e9:.2f}B")
    
    # IR 10B ìˆ˜ì§‘
    print(f"\nğŸ¯ IR ë°ì´í„° ìˆ˜ì§‘ (ëª©í‘œ: 10B)")
    pretrain_ir = []
    ir_tokens = 0
    ir_target = 10_000_000_000
    idx = 0
    
    while ir_tokens < ir_target and idx < len(all_samples):
        sample = all_samples[idx]
        pretrain_ir.append(sample)
        ir_tokens += sample['ir_tokens']
        idx += 1
    
    ir_end_idx = idx
    
    print(f"  âœ“ {ir_tokens:,} í† í° ({ir_tokens/1e9:.2f}B)")
    print(f"  âœ“ {len(pretrain_ir):,}ê°œ ìƒ˜í”Œ (idx 0-{ir_end_idx})")
    
    # ASM 10B ìˆ˜ì§‘
    print(f"\nğŸ¯ ASM ë°ì´í„° ìˆ˜ì§‘ (ëª©í‘œ: 10B)")
    pretrain_asm = []
    asm_tokens = 0
    asm_target = 10_000_000_000
    
    while asm_tokens < asm_target and idx < len(all_samples):
        sample = all_samples[idx]
        pretrain_asm.append(sample)
        asm_tokens += sample['asm_tokens']
        idx += 1
    
    asm_end_idx = idx
    
    print(f"  âœ“ {asm_tokens:,} í† í° ({asm_tokens/1e9:.2f}B)")
    print(f"  âœ“ {len(pretrain_asm):,}ê°œ ìƒ˜í”Œ (idx {ir_end_idx}-{asm_end_idx})")
    
    # í†µê³„
    print(f"\nğŸ“Š Pretraining ë°ì´í„°ì…‹:")
    print(f"  IR:  {ir_tokens:,} ({ir_tokens/1e9:.2f}B)")
    print(f"  ASM: {asm_tokens:,} ({asm_tokens/1e9:.2f}B)")
    print(f"  í•©ê³„: {ir_tokens + asm_tokens:,} ({(ir_tokens + asm_tokens)/1e9:.2f}B)")
    print(f"  ì´ ìƒ˜í”Œ: {len(pretrain_ir) + len(pretrain_asm):,}ê°œ")
    print(f"  ì‚¬ìš© ì¸ë±ìŠ¤: 0-{asm_end_idx} / {len(all_samples)}")
    
    remaining = len(all_samples) - asm_end_idx
    remaining_tokens = sum(s['total_tokens'] for s in all_samples[asm_end_idx:])
    print(f"\nğŸ“¦ ë‚¨ì€ ë°ì´í„°:")
    print(f"  ìƒ˜í”Œ: {remaining:,}ê°œ")
    print(f"  í† í°: {remaining_tokens:,} ({remaining_tokens/1e9:.2f}B)")
    
    # ì €ì¥
    output_dir = Path("pretraining_data")
    output_dir.mkdir(exist_ok=True)
    
    # IR ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
    with open(output_dir / "ir_samples.jsonl", 'w') as f:
        for sample in pretrain_ir:
            f.write(json.dumps({
                'file_id': sample['file_id'],
                'ir_path': sample['ir_path'],
                'tokens': sample['ir_tokens'],
                'parquet': sample['parquet']
            }) + '\n')
    
    # ASM ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
    with open(output_dir / "asm_samples.jsonl", 'w') as f:
        for sample in pretrain_asm:
            f.write(json.dumps({
                'file_id': sample['file_id'],
                'asm_path': sample['asm_path'],
                'tokens': sample['asm_tokens'],
                'parquet': sample['parquet']
            }) + '\n')
    
    # í†µê³„
    with open(output_dir / "stats.json", 'w') as f:
        json.dump({
            'ir_tokens': ir_tokens,
            'ir_samples': len(pretrain_ir),
            'asm_tokens': asm_tokens,
            'asm_samples': len(pretrain_asm),
            'total_tokens': ir_tokens + asm_tokens,
            'total_samples': len(pretrain_ir) + len(pretrain_asm),
            'used_indices': f"0-{asm_end_idx}",
            'remaining_samples': remaining,
            'remaining_tokens': remaining_tokens
        }, f, indent=2)
    
    # ë‚˜ì¤‘ ì‚¬ìš©ì„ ìœ„í•´ ë‚¨ì€ ìƒ˜í”Œ ì¸ë±ìŠ¤ ì €ì¥
    with open(output_dir / "remaining_indices.json", 'w') as f:
        json.dump({
            'start_idx': asm_end_idx,
            'end_idx': len(all_samples),
            'count': remaining
        }, f, indent=2)
    
    print(f"\nâœ“ ì €ì¥ ì™„ë£Œ: pretraining_data/")
    print(f"  - ir_samples.jsonl ({len(pretrain_ir):,}ê°œ)")
    print(f"  - asm_samples.jsonl ({len(pretrain_asm):,}ê°œ)")
    print(f"  - stats.json")
    print(f"  - remaining_indices.json")
    print("=" * 70)

if __name__ == "__main__":
    main()