"""
ComPile íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
5ê°œ ìƒ˜í”Œë¡œ Bitcode â†’ IR â†’ ASM ë³€í™˜ ë° í† í° ê³„ì‚° í…ŒìŠ¤íŠ¸
"""

import subprocess
import tempfile
import os
from pathlib import Path
from datasets import load_dataset
from transformers import AutoTokenizer

print("=" * 70)
print("ComPile íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (5ê°œ ìƒ˜í”Œ)")
print("=" * 70)

# 1. í•„ìš”í•œ ë„êµ¬ ì²´í¬
print("\nğŸ”§ í•„ìˆ˜ ë„êµ¬ í™•ì¸:")
try:
    result = subprocess.run(['clang', '--version'], capture_output=True, text=True, timeout=5)
    print(f"  âœ“ Clang: {result.stdout.split(chr(10))[0]}")
except:
    print("  âŒ Clang ì—†ìŒ")
    exit(1)

try:
    result = subprocess.run(['llvm-dis', '--version'], capture_output=True, text=True, timeout=5)
    print(f"  âœ“ llvm-dis ì„¤ì¹˜ë¨")
except:
    print("  âŒ llvm-dis ì—†ìŒ")
    exit(1)

# 2. í† í¬ë‚˜ì´ì € ë¡œë“œ
print("\nğŸ“¦ í† í¬ë‚˜ì´ì € ë¡œë“œ:")
tokenizer = AutoTokenizer.from_pretrained("bigcode/starcoderbase-1b")
print(f"  âœ“ StarCoder í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")

# 3. ë°ì´í„°ì…‹ ë¡œë“œ ë° í•„í„°ë§ (ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¹ ë¥´ê²Œ)
print("\nğŸ“¥ ë°ì´í„°ì…‹ ë¡œë“œ (C/C++ ë§Œ, ìŠ¤íŠ¸ë¦¬ë°):")
print("  - ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ í•„ìš”í•œ ê²ƒë§Œ ë°›ê¸°...")

ds = load_dataset('llvm-ml/ComPile', split='train', streaming=True)

ds = ds.filter(lambda x: x['language'] in ['C', 'C++'])

# 4. 5ê°œ ìƒ˜í”Œë§Œ ê°€ì ¸ì˜¤ê¸°
print(f"  âœ“ ì²˜ìŒ 5ê°œ C/C++ ìƒ˜í”Œ ìˆ˜ì§‘ ì¤‘...")
ds_sample = []
for i, row in enumerate(ds):
    if i >= 5:
        break
    ds_sample.append(row)
    print(f"    - ìƒ˜í”Œ {i+1} ìˆ˜ì§‘ ì™„ë£Œ")

print(f"  âœ“ í…ŒìŠ¤íŠ¸ìš© {len(ds_sample)}ê°œ ìƒ˜í”Œ ì¤€ë¹„ ì™„ë£Œ")

# 5. ë³€í™˜ í•¨ìˆ˜ë“¤
def bitcode_to_ir(bitcode):
    """Bitcode â†’ Textual IR"""
    try:
        dis_command = ['llvm-dis', '-']
        with subprocess.Popen(
            dis_command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            stdin=subprocess.PIPE
        ) as dis_process:
            output, error = dis_process.communicate(input=bitcode, timeout=10)
            if dis_process.returncode == 0:
                return output.decode('utf-8', errors='ignore')
            return None
    except:
        return None

def ir_to_asm(ir_text):
    """IR â†’ Assembly"""
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.ll', delete=False, encoding='utf-8') as f:
            f.write(ir_text)
            ir_file = f.name
        
        asm_file = ir_file.replace('.ll', '.s')
        
        result = subprocess.run(
            ['clang', '-S', ir_file, '-o', asm_file],
            capture_output=True,
            timeout=10,
            text=True
        )
        
        if result.returncode == 0 and Path(asm_file).exists():
            with open(asm_file, 'r', encoding='utf-8') as f:
                asm_content = f.read()
            
            os.unlink(ir_file)
            os.unlink(asm_file)
            return asm_content
        else:
            if Path(ir_file).exists():
                os.unlink(ir_file)
            if Path(asm_file).exists():
                os.unlink(asm_file)
            return None
    except:
        return None

def count_tokens(text):
    """í† í° ìˆ˜ ê³„ì‚°"""
    try:
        tokens = tokenizer.encode(text, add_special_tokens=False)
        return len(tokens)
    except:
        return len(text.split())

# 6. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
print("\n" + "=" * 70)
print("í…ŒìŠ¤íŠ¸ ì‹¤í–‰:")
print("=" * 70)

results = []
for i, row in enumerate(ds_sample, 1):
    print(f"\n[ìƒ˜í”Œ {i}] ì–¸ì–´: {row['language']}")
    
    # Bitcode â†’ IR
    print("  1ï¸âƒ£  Bitcode â†’ IR ë³€í™˜...", end=" ")
    ir_text = bitcode_to_ir(row['content'])
    
    if not ir_text:
        print("âŒ ì‹¤íŒ¨")
        continue
    
    ir_size = len(ir_text)
    ir_tokens = count_tokens(ir_text)
    print(f"âœ“ ({ir_size:,} bytes, {ir_tokens:,} tokens)")
    
    # IR â†’ ASM
    print("  2ï¸âƒ£  IR â†’ Assembly ë³€í™˜...", end=" ")
    asm_text = ir_to_asm(ir_text)
    
    if not asm_text:
        print("âŒ ì‹¤íŒ¨")
        continue
    
    asm_size = len(asm_text)
    asm_tokens = count_tokens(asm_text)
    print(f"âœ“ ({asm_size:,} bytes, {asm_tokens:,} tokens)")
    
    total_tokens = ir_tokens + asm_tokens
    
    # ê²°ê³¼ ì €ì¥
    results.append({
        'sample': i,
        'language': row['language'],
        'ir_size': ir_size,
        'ir_tokens': ir_tokens,
        'asm_size': asm_size,
        'asm_tokens': asm_tokens,
        'total_tokens': total_tokens
    })
    
    print(f"  ğŸ“Š í•©ê³„: {total_tokens:,} tokens")

# 7. ìµœì¢… í†µê³„
print("\n" + "=" * 70)
print("í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
print("=" * 70)

if results:
    print(f"\nâœ… ì„±ê³µ: {len(results)}/5 ìƒ˜í”Œ\n")
    
    print("ìƒì„¸ ê²°ê³¼:")
    print("-" * 70)
    print(f"{'ìƒ˜í”Œ':<6} {'ì–¸ì–´':<8} {'IR Tokens':<12} {'ASM Tokens':<12} {'Total':<12}")
    print("-" * 70)
    
    total_ir_tokens = 0
    total_asm_tokens = 0
    total_all_tokens = 0
    
    for r in results:
        print(f"{r['sample']:<6} {r['language']:<8} {r['ir_tokens']:<12,} {r['asm_tokens']:<12,} {r['total_tokens']:<12,}")
        total_ir_tokens += r['ir_tokens']
        total_asm_tokens += r['asm_tokens']
        total_all_tokens += r['total_tokens']
    
    print("-" * 70)
    print(f"{'í•©ê³„':<6} {'':<8} {total_ir_tokens:<12,} {total_asm_tokens:<12,} {total_all_tokens:<12,}")
    print("-" * 70)
    
    print(f"\nğŸ¯ 5ê°œ ìƒ˜í”Œ ì´ í† í°: {total_all_tokens:,}")
    print(f"   - IR: {total_ir_tokens:,}")
    print(f"   - ASM: {total_asm_tokens:,}")
    print(f"\nğŸ’¡ í‰ê·  í† í° per ìƒ˜í”Œ: {total_all_tokens / len(results):,.0f}")
else:
    print("âŒ ëª¨ë“  ìƒ˜í”Œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")