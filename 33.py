"""
ComPile Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îã®Ïùº parquet ÌååÏùº ÌÖåÏä§Ìä∏
Ìïú Í∞ú parquet ÌååÏùº ‚Üí IR/Assembly/ÌÜ†ÌÅ∞ ÏÉùÏÑ±
"""

import os
import json
import subprocess
import tempfile
import pandas as pd
from pathlib import Path
from transformers import AutoTokenizer
from tqdm import tqdm
import sys

# ÌôòÍ≤Ω ÏÑ§Ï†ï
os.environ['HF_HOME'] = '/Volumes/My Passport for Mac/cache/huggingface'

os.environ['TOKENIZERS_PARALLELISM'] = 'false'
# ÏÑ§Ï†ï
PARQUET_DIR = Path("/Volumes/My Passport for Mac/cache/huggingface/hub/datasets--llvm-ml--ComPile/blobs")
OUTPUT_DIR = Path("./test_single_parquet_output")
CLANG_PATH = "clang"

# Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
IR_DIR = OUTPUT_DIR / "ir"
ASM_DIR = OUTPUT_DIR / "asm"
IR_DIR.mkdir(exist_ok=True)
ASM_DIR.mkdir(exist_ok=True)


class SingleParquetProcessor:
    def __init__(self):
        self.ir_dir = IR_DIR
        self.asm_dir = ASM_DIR
        self.metadata_file = OUTPUT_DIR / "metadata.jsonl"

        self.parquet_index = int(sys.argv[1]) if len(sys.argv) > 1 else 0
        
        print("üì¶ StarCoder ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎî©...")
        self.tokenizer = AutoTokenizer.from_pretrained("bigcode/starcoderbase-1b")
        
        self.stats = {
            "total_tokens": 0,
            "ir_tokens": 0,
            "asm_tokens": 0,
            "processed_files": 0,
            "success_files": 0,
            "failed_files": 0,
            "failed_reasons": {}
        }
    
    def bitcode_to_textual_ir(self, bitcode):
        """Bitcode ‚Üí ÌÖçÏä§Ìä∏ IR"""
        try:
            dis_command = ['llvm-dis', '-']
            with subprocess.Popen(
                dis_command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                stdin=subprocess.PIPE
            ) as dis_process:
                output, error = dis_process.communicate(input=bitcode, timeout=10)
                
                if dis_process.returncode == 0:
                    return output.decode('utf-8', errors='ignore')
                else:
                    return None
        except Exception as e:
            return None
    
    def ir_to_assembly(self, ir_text, debug=False):
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.ll', 
                                            delete=False, encoding='utf-8') as f:
                f.write(ir_text)
                ir_file = f.name

            asm_file = ir_file.replace('.ll', '.s')

            if debug:
                print(f"\nüîç Debug Info:")
                print(f"   IR file: {ir_file}")
                print(f"   ASM file: {asm_file}")
                print(f"   IR exists: {Path(ir_file).exists()}")

            result = subprocess.run(
<<<<<<< HEAD
                [CLANG_PATH, '-S', '-target', 'x86_64-unknown-linux-gnu',ir_file, '-o', asm_file],
=======
                [CLANG_PATH, '-S', ir_file, '-o', asm_file],
>>>>>>> 8658184119bfd78f3162d0ca933022bc6eb3cd47
                capture_output=True,
                timeout=10,
                text=True
            )

            if debug:
                print(f"   Return code: {result.returncode}")
                print(f"   ASM exists after run: {Path(asm_file).exists()}")
<<<<<<< HEAD
                if result.stderr:
                     print(f"   STDERR: {result.stderr[:500]}") 
=======
>>>>>>> 8658184119bfd78f3162d0ca933022bc6eb3cd47

            if Path(asm_file).exists():
                with open(asm_file, 'r', encoding='utf-8') as f:
                    asm_content = f.read()

                if debug:
                    print(f"   ASM size: {len(asm_content)} bytes")

                os.unlink(ir_file)
                os.unlink(asm_file)
                return asm_content
            else:
                if debug:
                    print(f"   ‚ùå ASM file not found!")
                if Path(ir_file).exists():
                    os.unlink(ir_file)
                return None

        except Exception as e:
            if debug:
                print(f"\n‚ùå Exception: {e}")
            return None
    
    def count_tokens(self, text):
        """ÌÜ†ÌÅ∞ Ïàò Í≥ÑÏÇ∞"""
        try:
            tokens = self.tokenizer.encode(text, add_special_tokens=False)
            return len(tokens)
        except:
            return len(text.split())
    
    def process_single_file(self, row, file_id, debug_first_fail=True):
        """Îã®Ïùº ÌååÏùº Ï≤òÎ¶¨"""
        try:
            # 1. Bitcode ‚Üí IR
            bitcode = row['content']
            ir_text = self.bitcode_to_textual_ir(bitcode)
            
            if not ir_text or len(ir_text) < 50:
                self.stats['failed_reasons']['bitcode_conversion'] = \
                    self.stats['failed_reasons'].get('bitcode_conversion', 0) + 1
                return False
            
            # 2. IR ‚Üí Assembly
            asm_text = self.ir_to_assembly(ir_text, debug=debug_first_fail)
            
            if not asm_text or len(asm_text) < 50:
                self.stats['failed_reasons']['ir_to_asm'] = \
                    self.stats['failed_reasons'].get('ir_to_asm', 0) + 1
                return False
            
            # 3. ÌååÏùº Ï†ÄÏû•
            file_id_str = f"{file_id:06d}"
            
            ir_path = self.ir_dir / f"{file_id_str}.ll"
            with open(ir_path, 'w', encoding='utf-8') as f:
                f.write(ir_text)
            
            asm_path = self.asm_dir / f"{file_id_str}.s"
            with open(asm_path, 'w', encoding='utf-8') as f:
                f.write(asm_text)
            
            # 4. ÌÜ†ÌÅ∞ Ïàò Í≥ÑÏÇ∞
            ir_tokens = self.count_tokens(ir_text)
            asm_tokens = self.count_tokens(asm_text)
            
            # 5. Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
            metadata = {
                "file_id": file_id_str,
                "language": row.get('language', 'unknown'),
                "ir_tokens": ir_tokens,
                "asm_tokens": asm_tokens,
                "total_tokens": ir_tokens + asm_tokens,
                "ir_path": str(ir_path),
                "asm_path": str(asm_path),
                "license": row.get('license_expression', 'unknown')
            }
            
            with open(self.metadata_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(metadata) + '\n')
            
            # 6. ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
            self.stats['ir_tokens'] += ir_tokens
            self.stats['asm_tokens'] += asm_tokens
            self.stats['total_tokens'] = self.stats['ir_tokens'] + self.stats['asm_tokens']
            self.stats['success_files'] += 1
            
            return True
            
        except Exception as e:
            self.stats['failed_reasons']['exception'] = \
                self.stats['failed_reasons'].get('exception', 0) + 1
            return False
    
    def run(self):
        """Î©îÏù∏ Ïã§Ìñâ"""
        print("=" * 70)
        print("Îã®Ïùº Parquet ÌååÏùº ÌÖåÏä§Ìä∏")
        print("=" * 70)
        
        # Clang/llvm-dis Ï≤¥ÌÅ¨
        try:
            subprocess.run([CLANG_PATH, '--version'], 
                          capture_output=True, text=True, timeout=5)
            print(f"‚úì Clang Î∞úÍ≤¨")
        except:
            print("‚ùå ClangÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")
            return
        
        try:
            subprocess.run(['llvm-dis', '--version'], 
                          capture_output=True, text=True, timeout=5)
            print(f"‚úì llvm-dis Î∞úÍ≤¨\n")
        except:
            print("‚ùå llvm-disÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")
            return
        
        # Ï≤´ Î≤àÏß∏ blob ÌååÏùº Ï∞æÍ∏∞ (Ìï¥ÏãúÍ∞íÏúºÎ°ú Ï†ÄÏû•Îê®)
        blob_files = [f for f in PARQUET_DIR.glob("*") if f.is_file() and not f.name.startswith('.')]
        
        if not blob_files:
            print("‚ùå blob ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")
            print(f"Í≤ΩÎ°ú: {PARQUET_DIR}")
            return
        
        parquet_file = blob_files[self.parquet_index]
        print(f"üì• Parquet ÌååÏùº Î°úÎìú: {parquet_file.name}")
        print(f"   Í≤ΩÎ°ú: {parquet_file}")
        
        # Parquet ÌååÏùº ÏùΩÍ∏∞
        try:
            df = pd.read_parquet(parquet_file)
            print(f"‚úì Î°úÎìú ÏôÑÎ£å: {len(df):,}Í∞ú ÏÉòÌîå\n")
        except Exception as e:
            print(f"‚ùå Parquet ÌååÏùº ÏùΩÍ∏∞ Ïã§Ìå®: {e}")
            return
        
        # Ï≤òÎ¶¨
        print(f"üöÄ Ï≤òÎ¶¨ ÏãúÏûë...\n")
        
        pbar = tqdm(total=len(df), desc="ÏßÑÌñâ", unit="files")
        
        for idx, (_, row) in enumerate(df.iterrows()):
            self.stats['processed_files'] += 1
            
            success = self.process_single_file(row, idx)
            
            if success:
                pbar.update(1)
                pbar.set_postfix({
                    'Success': self.stats['success_files'],
                    'Fail': self.stats['failed_files'],
                    'Tokens': f"{self.stats['total_tokens']:,}"
                })
            else:
                self.stats['failed_files'] += 1
                pbar.update(1)
        
        pbar.close()
        
        # ÏµúÏ¢Ö ÌÜµÍ≥Ñ
        self.print_final_stats()
    
    def print_final_stats(self):
        """ÏµúÏ¢Ö ÌÜµÍ≥Ñ"""
        print("\n" + "=" * 70)
        print("ÏôÑÎ£å!")
        print("=" * 70)
        print(f"Ï≤òÎ¶¨Îêú ÌååÏùº:      {self.stats['processed_files']:,}")
        print(f"ÏÑ±Í≥µ:            {self.stats['success_files']:,}")
        print(f"Ïã§Ìå®:            {self.stats['failed_files']:,}")
        print(f"ÏÑ±Í≥µÎ•†:          {self.stats['success_files']*100/(self.stats['processed_files'] or 1):.1f}%")
        
        print(f"\nÌÜ†ÌÅ∞ Ïàò (StarCoder ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä):")
        print(f"  IR ÌÜ†ÌÅ∞:       {self.stats['ir_tokens']:,}")
        print(f"  ASM ÌÜ†ÌÅ∞:      {self.stats['asm_tokens']:,}")
        print(f"  Ï¥ù ÌÜ†ÌÅ∞:       {self.stats['total_tokens']:,}")
        
        print(f"\nÏã§Ìå® ÏõêÏù∏:")
        for reason, count in self.stats['failed_reasons'].items():
            print(f"  {reason}: {count:,}")
        
        print(f"\nÏ∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨:   {OUTPUT_DIR}")
        print(f"  - IR:          {self.ir_dir}")
        print(f"  - Assembly:    {self.asm_dir}")
        print(f"  - Metadata:    {self.metadata_file}")


if __name__ == "__main__":
    processor = SingleParquetProcessor()
    processor.run()