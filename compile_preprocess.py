"""
ComPile ë°ì´í„°ì…‹ì˜ ë‹¨ì¼ parquet íŒŒì¼ í…ŒìŠ¤íŠ¸
í•œ ê°œ parquet íŒŒì¼ â†’ IR/Assembly/í† í° ìƒì„±
ê° parquetì€ ë³„ë„ í´ë”ì— ì €ì¥ (ë®ì–´ì“°ê¸° ë°©ì§€)
"""

import os
import sys
import json
import subprocess
import tempfile
import pandas as pd
from pathlib import Path
from transformers import AutoTokenizer
from tqdm import tqdm

# í™˜ê²½ ì„¤ì •
os.environ['HF_HOME'] = '/Volumes/My Passport for Mac/cache/huggingface'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# ì„¤ì •
PARQUET_DIR = Path("/Volumes/My Passport for Mac/cache/huggingface/hub/datasets--llvm-ml--ComPile/blobs")
CLANG_PATH = "/usr/local/opt/llvm/bin/clang"


class SingleParquetProcessor:
    def __init__(self, parquet_index=0):
        self.parquet_index = parquet_index
        
        # ê° parquetë³„ë¡œ ë‹¤ë¥¸ í´ë”ì— ì €ì¥
        self.base_dir = Path(f"./test_parquet_{parquet_index}")
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        self.ir_dir = self.base_dir / "ir"
        self.asm_dir = self.base_dir / "asm"
        self.metadata_file = self.base_dir / "metadata.jsonl"
        
        self.ir_dir.mkdir(exist_ok=True)
        self.asm_dir.mkdir(exist_ok=True)
        
        print("ğŸ“¦ StarCoder í† í¬ë‚˜ì´ì € ë¡œë”©...")
        self.tokenizer = AutoTokenizer.from_pretrained("bigcode/starcoderbase-1b")
        
        self.stats = {
            "total_tokens": 0,
            "ir_tokens": 0,
            "asm_tokens": 0,
            "processed_files": 0,
            "success_files": 0,
            "failed_files": 0,
            "failed_reasons": {}
        }
    
    def bitcode_to_textual_ir(self, bitcode):
        """Bitcode â†’ í…ìŠ¤íŠ¸ IR"""
        try:
            dis_command = ['llvm-dis', '-']
            with subprocess.Popen(
                dis_command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                stdin=subprocess.PIPE
            ) as dis_process:
                output, error = dis_process.communicate(input=bitcode, timeout=10)
                
                if dis_process.returncode == 0:
                    return output.decode('utf-8', errors='ignore')
                else:
                    return None
        except Exception as e:
            return None
    
    def ir_to_assembly(self, ir_text, debug=False):
        """IR â†’ Assembly"""
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.ll', 
                                            delete=False, encoding='utf-8') as f:
                f.write(ir_text)
                ir_file = f.name
            
            asm_file = ir_file.replace('.ll', '.s')
            
            if debug:
                print(f"\nğŸ” Debug Info:")
                print(f"   IR file: {ir_file}")
                print(f"   ASM file: {asm_file}")
                print(f"   IR exists: {Path(ir_file).exists()}")
            
            result = subprocess.run(
                [CLANG_PATH, '-S', '-target', 'x86_64-unknown-linux-gnu', ir_file, '-o', asm_file],
                capture_output=True,
                timeout=10,
                text=True
            )
            
            if debug:
                print(f"   Return code: {result.returncode}")
                print(f"   ASM exists after run: {Path(asm_file).exists()}")
                if result.stderr:
                    print(f"   STDERR: {result.stderr[:500]}")
            
            if Path(asm_file).exists():
                with open(asm_file, 'r', encoding='utf-8') as f:
                    asm_content = f.read()
                
                if debug:
                    print(f"   ASM size: {len(asm_content)} bytes")
                
                os.unlink(ir_file)
                os.unlink(asm_file)
                return asm_content
            else:
                if debug:
                    print(f"   âŒ ASM file not found!")
                if Path(ir_file).exists():
                    os.unlink(ir_file)
                return None
                
        except Exception as e:
            if debug:
                print(f"\nâŒ Exception: {e}")
            return None
    
    def count_tokens(self, text):
        """í† í° ìˆ˜ ê³„ì‚°"""
        try:
            tokens = self.tokenizer.encode(text, add_special_tokens=False)
            return len(tokens)
        except:
            return len(text.split())
    
    def process_single_file(self, row, file_id, debug_first_fail=False):
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        try:
            # 1. Bitcode â†’ IR
            bitcode = row['content']
            ir_text = self.bitcode_to_textual_ir(bitcode)
            
            if not ir_text or len(ir_text) < 50:
                self.stats['failed_reasons']['bitcode_conversion'] = \
                    self.stats['failed_reasons'].get('bitcode_conversion', 0) + 1
                return False
            
            # 2. IR â†’ Assembly
            asm_text = self.ir_to_assembly(ir_text, debug=debug_first_fail)
            
            if not asm_text or len(asm_text) < 50:
                self.stats['failed_reasons']['ir_to_asm'] = \
                    self.stats['failed_reasons'].get('ir_to_asm', 0) + 1
                return False
            
            # 3. íŒŒì¼ ì €ì¥
            file_id_str = f"{file_id:06d}"
            
            ir_path = self.ir_dir / f"{file_id_str}.ll"
            with open(ir_path, 'w', encoding='utf-8') as f:
                f.write(ir_text)
            
            asm_path = self.asm_dir / f"{file_id_str}.s"
            with open(asm_path, 'w', encoding='utf-8') as f:
                f.write(asm_text)
            
            # 4. í† í° ìˆ˜ ê³„ì‚°
            ir_tokens = self.count_tokens(ir_text)
            asm_tokens = self.count_tokens(asm_text)
            
            # 5. ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                "file_id": file_id_str,
                "language": row.get('language', 'unknown'),
                "ir_tokens": ir_tokens,
                "asm_tokens": asm_tokens,
                "total_tokens": ir_tokens + asm_tokens,
                "ir_path": str(ir_path),
                "asm_path": str(asm_path),
                "license": row.get('license_expression', 'unknown')
            }
            
            with open(self.metadata_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(metadata) + '\n')
            
            # 6. í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['ir_tokens'] += ir_tokens
            self.stats['asm_tokens'] += asm_tokens
            self.stats['total_tokens'] = self.stats['ir_tokens'] + self.stats['asm_tokens']
            self.stats['success_files'] += 1
            
            return True
            
        except Exception as e:
            self.stats['failed_reasons']['exception'] = \
                self.stats['failed_reasons'].get('exception', 0) + 1
            return False
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print("=" * 70)
        print("ë‹¨ì¼ Parquet íŒŒì¼ í…ŒìŠ¤íŠ¸")
        print(f"Parquet ì¸ë±ìŠ¤: {self.parquet_index}")
        print(f"ì¶œë ¥ í´ë”: {self.base_dir}")
        print("=" * 70)
        
        # Clang/llvm-dis ì²´í¬
        try:
            subprocess.run([CLANG_PATH, '--version'], 
                          capture_output=True, text=True, timeout=5)
            print(f"âœ“ Clang ë°œê²¬")
        except:
            print("âŒ Clangì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        try:
            subprocess.run(['llvm-dis', '--version'], 
                          capture_output=True, text=True, timeout=5)
            print(f"âœ“ llvm-dis ë°œê²¬\n")
        except:
            print("âŒ llvm-disë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        # Parquet íŒŒì¼ ì°¾ê¸° (ì •ë ¬ëœ ìˆœì„œ)
        blob_files = sorted([f for f in PARQUET_DIR.glob("*") if f.is_file() and not f.name.startswith('.')])
        
        if not blob_files:
            print("âŒ blob íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print(f"ê²½ë¡œ: {PARQUET_DIR}")
            return
        
        if self.parquet_index >= len(blob_files):
            print(f"âŒ ì¸ë±ìŠ¤ {self.parquet_index}ëŠ” ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤!")
            print(f"   ì´ íŒŒì¼ ìˆ˜: {len(blob_files)}")
            return
        
        parquet_file = blob_files[self.parquet_index]
        print(f"ğŸ“¥ Parquet íŒŒì¼ ë¡œë“œ (ì¸ë±ìŠ¤ {self.parquet_index}): {parquet_file.name}")
        print(f"   ê²½ë¡œ: {parquet_file}")
        
        # Parquet íŒŒì¼ ì½ê¸°
        try:
            df = pd.read_parquet(parquet_file)
            print(f"âœ“ ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ìƒ˜í”Œ\n")
        except Exception as e:
            print(f"âŒ Parquet íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            return
        
        # ì²˜ë¦¬
        print(f"ğŸš€ ì²˜ë¦¬ ì‹œì‘...\n")
        
        pbar = tqdm(total=len(df), desc="ì§„í–‰", unit="files")
        
        for idx, (_, row) in enumerate(df.iterrows()):
            self.stats['processed_files'] += 1
            
            success = self.process_single_file(row, idx, debug_first_fail=(idx < 10))
            
            if success:
                pbar.update(1)
                pbar.set_postfix({
                    'Success': self.stats['success_files'],
                    'Fail': self.stats['failed_files'],
                    'Tokens': f"{self.stats['total_tokens']:,}"
                })
            else:
                self.stats['failed_files'] += 1
                pbar.update(1)
        
        pbar.close()
        
        # ìµœì¢… í†µê³„
        self.print_final_stats()
    
    def print_final_stats(self):
        """ìµœì¢… í†µê³„"""
        print("\n" + "=" * 70)
        print("ì™„ë£Œ!")
        print("=" * 70)
        print(f"ì²˜ë¦¬ëœ íŒŒì¼:      {self.stats['processed_files']:,}")
        print(f"ì„±ê³µ:            {self.stats['success_files']:,}")
        print(f"ì‹¤íŒ¨:            {self.stats['failed_files']:,}")
        print(f"ì„±ê³µë¥ :          {self.stats['success_files']*100/(self.stats['processed_files'] or 1):.1f}%")
        
        print(f"\ní† í° ìˆ˜ (StarCoder í† í¬ë‚˜ì´ì €):")
        print(f"  IR í† í°:       {self.stats['ir_tokens']:,}")
        print(f"  ASM í† í°:      {self.stats['asm_tokens']:,}")
        print(f"  ì´ í† í°:       {self.stats['total_tokens']:,}")
        
        print(f"\nì‹¤íŒ¨ ì›ì¸:")
        for reason, count in self.stats['failed_reasons'].items():
            print(f"  {reason}: {count:,}")
        
        print(f"\nì¶œë ¥ ë””ë ‰í† ë¦¬:   {self.base_dir}")
        print(f"  - IR:          {self.ir_dir}")
        print(f"  - Assembly:    {self.asm_dir}")
        print(f"  - Metadata:    {self.metadata_file}")


if __name__ == "__main__":
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¡œ parquet ì¸ë±ìŠ¤ ë°›ê¸°
    parquet_index = int(sys.argv[1]) if len(sys.argv) > 1 else 0
    
    processor = SingleParquetProcessor(parquet_index=parquet_index)
    processor.run()